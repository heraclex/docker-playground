
version: '3.1'
services:

  centos8:
    build:
      context: ./centos8
      dockerfile: Dockerfile
    image: local/centos8
    container_name: centos8
    volumes:
      - ./.storage/shared:/root/shared

  zookeeper0:
    container_name: zookeeper0
    image: zookeeper:3.5.9
    ports:
      - "2181:2181"
    restart: unless-stopped
    hostname: zookeeper0
    volumes:
      - ./.storage/zookeeper/data:/data
      - ./.storage/zookeeper/datalog:/datalog

  # Fully manage kafka node and can be modified
  kafka0:
    container_name: kafka0
    hostname: kafka0
    build: 
      context: ./kafka
      dockerfile: Dockerfile
    image: local/kafka
    ports:
      - 9092:9092
      - 9997:9997
    environment:
      # DOCKER_API_VERSION: 1.22
      KAFKA_ADVERTISED_HOST_NAME: 192.168.99.100
      # Required. Kafka will publish this address to ZooKeeper so clients know
      # how to get in touch with Kafka. "PLAINTEXT" indicates that no authentication
      # mechanism will be used.
      KAFKA_ADVERTISED_LISTENERS: "PLAINTEXT://kafka0:9092"
      # Required. Instructs Kafka how to get in touch with ZooKeeper.
      KAFKA_ZOOKEEPER_CONNECT: zookeeper0:2181
      # Required when running in a single-node cluster, as we are. We would be able to take the default if we had
      # three or more nodes in the cluster.
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      #   name:partitions:replicas:cleanup.policy
      # cleanup.policy=>https://docs.confluent.io/platform/current/installation/configuration/topic-configs.html#topicconfigs_cleanup.policy
      KAFKA_CREATE_TOPICS: mytopic-1:1:1:delete, mytopic-2:1:1:delete
      # Kafka Monitoring and Metrics Using JMX
      JMX_PORT: 9997
      KAFKA_JMX_OPTS: -Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=kafka0 -Dcom.sun.management.jmxremote.rmi.port=9997
    volumes:
      - ./.storage/kafka/var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped
    depends_on:
      - zookeeper0
  
  # Kafka Connect, an open source component of Apache Kafka,
  # is a framework for connecting Kafka with external systems
  # such as databases, key-value stores, search indexes, and file systems.
  # https://docs.confluent.io/current/connect/index.html
  kafka-connect0:
    image: confluentinc/cp-kafka-connect:7.0.1
    container_name: kafka-connect0
    hostname: kafka-connect0
    ports:
      - 8083:8083
    environment:
      # Required.
      # The list of Kafka brokers to connect to. This is only used for bootstrapping,
      # the addresses provided here are used to initially connect to the cluster,
      # after which the cluster can dynamically change. Thanks, ZooKeeper!
      CONNECT_BOOTSTRAP_SERVERS: "kafka0:9092"
      # Required. A unique string that identifies the Connect cluster group this worker belongs to.
      CONNECT_GROUP_ID: compose-connect-group
      # Connect will actually use Kafka topics as a datastore for configuration and other data. #meta
      # Required. The name of the topic where connector and task configuration data are stored.
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      # Required. The name of the topic where connector and task configuration offsets are stored.
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      # Required. The name of the topic where connector and task configuration status updates are stored.
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      # Required. Converter class for key Connect data. This controls the format of the
      # data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
      
      # Allows connect to leverage the power of schema registry. Here we define it for key schemas.
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry0:8081'
      
      # Required. Converter class for value Connect data. This controls the format of the
      # data that will be written to Kafka for source connectors or read from Kafka for sink connectors.
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
      
      # Allows connect to leverage the power of schema registry. Here we define it for value schemas.
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: 'http://schema-registry0:8081'

      # Required. Converter class for internal key Connect data that implements the Converter interface.
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Required. Converter class for offset value Connect data that implements the Converter interface.
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      # Required. The hostname that will be given out to other workers to connect to.
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      # The next three are required when running in a single-node cluster, as we are.
      # We would be able to take the default (of 3) if we had three or more nodes in the cluster.
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
    # kafka-connect relies upon Kafka and ZooKeeper.
    # This will instruct docker to wait until those services are up
    # before attempting to start kafka-connect.
    depends_on:
      - zookeeper0
      - kafka0

  # Written and open sourced by Confluent, the Schema Registry for Apache Kafka enables
  # developers to define standard schemas for their events, share them across the
  # organization and safely evolve them in a way that is backward compatible and future proof.
  # https://www.confluent.io/confluent-schema-registry/
  schema-registry0:
    image: confluentinc/cp-schema-registry:7.0.1
    container_name: schema-registry0
    hostname: schema-registry0
    # restart: unless-stopped
    ports:
      - 8081:8081
    environment:
      # Required. Schema Registry will contact ZooKeeper to figure out how to connect
      # to the Kafka cluster.
      SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper0:2181
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka0:9092"

      # Required. This is the hostname that Schema Registry will advertise in ZooKeeper.
      SCHEMA_REGISTRY_HOST_NAME: schema-registry0
    # Schema Registry relies upon both Kafka and ZooKeeper. This will instruct docker to wait
    # until the zookeeper and kafka services are up before attempting to start Schema Registry.
    depends_on:
      - zookeeper
      - kafka0
  
  kafka-ui:
    container_name: kafka-ui
    image: provectuslabs/kafka-ui:latest
    ports:
      - 8080:8080
    depends_on:
      - zookeeper
      - kafka0
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka0:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper0:2181
      KAFKA_CLUSTERS_0_JMXPORT: 9997
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry0:8081
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: first
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://kafka-connect0:8083
      # KAFKA_CLUSTERS_0_PROPERTIES_SECURITY_PROTOCOL: SASL_PLAINTEXT
      # KAFKA_CLUSTERS_0_PROPERTIES_SASL_MECHANISM: PLAIN
      # KAFKA_CLUSTERS_0_PROPERTIES_SASL_JAAS_CONFIG: 'org.apache.kafka.common.security.plain.PlainLoginModule required username="admin" password="admin-secret";'  